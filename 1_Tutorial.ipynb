{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7310ad49-35e6-4c93-8746-7a5e36566f6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ea6c2a-50f8-49df-8063-009f60949abf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## List Files Using DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca10908d-2e6d-48f8-9efc-0fd3763c7d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/Volumes/workspace/learn/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8c35868-ccba-4c8c-b393-ae6e30815154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load File using spark\n",
    "It stores the file as a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c977a38-b404-40c3-aa81-3e26e5f37610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e45b6f-4b23-49a2-b61c-7153c284c173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1= spark.read.format('csv')\\\n",
    "    .option('inferSchema', True)\\\n",
    "        .option('header', True)\\\n",
    "            .load('/Volumes/workspace/learn/test_volume/BigMart Sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc4b2a5c-1b50-4872-bb2d-548b148c49d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c5797a5-b518-4493-911f-00baa44d1c09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2= spark.read.format('json')\\\n",
    "    .option('inferSchema', True)\\\n",
    "        .option('header', True)\\\n",
    "            .load('/Volumes/workspace/learn/test_volume/drivers.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "430d2751-3e61-4939-8724-6cdcfefeb195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Display spark dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6353787-a659-43cf-9fdc-b2f5cf46f258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using display\n",
    "It is a databricks only function <br/>\n",
    "> NOTE: Outputs are interactive and pretty printed\n",
    "\n",
    "Examples:\n",
    "* `display(df)`\n",
    "* `df.display()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1937fb0f-65a6-4bfb-b6dd-1bd18c7fec01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a1e847-f0bb-4f40-86c0-59ad82f7d6ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using show \n",
    "`df.show()`\n",
    "> NOTE: Output is not pretty printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b3dda9-ee58-48c0-9046-f8554a1fa052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.show(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "934328ee-5e95-400c-ba60-47c80ec8f19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Displaying ranged values\n",
    "\n",
    "Pyspark does not support pandas' iLoc because its based on a distributed architechture. It has different workarounds (might cost more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "524a9ea1-4af9-4054-9181-bd547a5422d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Top N records\n",
    "\n",
    "Lazy evaulation: limit <br/>\n",
    "Immediate evaluation (trigger): head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275fa369-cb1d-407a-a111-95d2454ba025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1.limit(2)\n",
    "#lazy evaluation: returns a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a20800-e962-45c0-ac7d-a786ec662bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1.head(2)\n",
    "# immediate evaluation: returns a list of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24a39cbc-b4e8-4d4e-8934-d706df63f9bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Bottom N records\n",
    "\n",
    "Pyspark only supports immediate action using tail method <br/>\n",
    "**We have ```select top 10 * from tbl```, and not ```select bottom 10 * from tbl```**\n",
    "\n",
    "Lazy evaulation is not possible here due to lack of global ordering (since it is distributed) <br />\n",
    "Workaround? orderBy desc and then limit x (expensive)\n",
    "\n",
    "> NOTE: both might return different outputs. To achieve correctess, one need to determine grain of the table and then order (in both cases), as tail does not deremine correctness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b6d7333-cb1b-4b15-872b-1ed2c6fa0077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df1.orderBy(df1.Item_Identifier.asc()).tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d00e748-6453-4c12-8d08-113120ee87c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# select top 2 * from df1 order by Item_Identifier desc\n",
    "display(df1.orderBy(df1.Item_Identifier.desc()).limit(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02687257-d634-4532-9a9b-c05124c754f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using custom range [x,y)\n",
    "\n",
    "Not supported in pyspark\n",
    "Pandas library supports it using iloc\n",
    "\n",
    "Workaround: Use window function with global ordering.\n",
    "> **Leads to single partition calculation and can cause serious performance degradation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17e8d0ee-06f3-453b-8dbf-14a54d9f905d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# [x,y) x inclusive y exclusive\n",
    "x, y = 5, 10\n",
    "\n",
    "# window function. cannot use partitionBy because it group values and then return same value\n",
    "w = Window\\\n",
    "    .orderBy(df1.Item_Identifier)   # replace \"col\" with the column you want to order by\n",
    "\n",
    "# Add row numbers starting at 1\n",
    "df_with_rn = df1.withColumn('row_num', row_number().over(w))\n",
    "\n",
    "# Filter rows in the range [x, y)\n",
    "result = df_with_rn.filter((df_with_rn.row_num >= x) & (df_with_rn.row_num < y)) \\\n",
    "                   .drop(df_with_rn.row_num)\n",
    "\n",
    "# display\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d47b238d-2948-4d6b-b9e5-270463f38f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c022ec77-f9bf-48e1-b160-fcaffeeb5c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Schema Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9449d332-ca42-4383-b1ab-eeb1f6bd66e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb4c20a7-aed4-4bed-a9e1-8985e42c2609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7989fced-d969-44e4-839b-19c16529d0ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define schema manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7c60137-95bd-47fa-81ed-fab6ac949663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### DDL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52d52ff6-9db8-4121-937c-211ddd344d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# changing Item_Weight from double to string\n",
    "my_ddl_schema = '''\n",
    "    Item_Identifier string,\n",
    "    Item_Weight string,\n",
    "    Item_Fat_Content string,\n",
    "    Item_Visibility double,\n",
    "    Item_Type string,\n",
    "    Item_MRP double,\n",
    "    Outlet_Identifier string,\n",
    "    Outlet_Establishment_Year int,\n",
    "    Outlet_Size string,\n",
    "    Outlet_Location_Type string,\n",
    "    Outlet_Type string,\n",
    "    Item_Outlet_Sales double\n",
    "'''\n",
    "\n",
    "df1_custom_type=spark.read.format('csv')\\\n",
    "  .schema(my_ddl_schema) \\\n",
    "    .option('header', True) \\\n",
    "      .load('/Volumes/workspace/learn/test_volume/BigMart Sales.csv')\n",
    "\n",
    "\n",
    "display(df1_custom_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d090c1-466c-4f21-bc24-44a3b70bf7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1_custom_type.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3485caf8-8287-453d-bd59-09892cac2c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### StructType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e40804-da56-40ef-a797-8ff78bd60335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82fb0c4-9169-46ea-8e9c-12afde7df278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Syntax: StructField('col_name', type(), nullable_boolean)\n",
    "my_struct_schema = T.StructType([\n",
    "    T.StructField('Item_Identifier', T.StringType(), True),\n",
    "    T.StructField('Item_Weight', T.StringType(), True),\n",
    "    T.StructField('Item_Fat_Content', T.StringType(), True),\n",
    "    T.StructField('Item_Visibility', T.StringType(), True),\n",
    "    T.StructField('Item_Type', T.StringType(), True),\n",
    "    T.StructField('Item_MRP', T.StringType(), True),\n",
    "    T.StructField('Outlet_Identifier', T.StringType(), True),\n",
    "    T.StructField('Outlet_Establishment_Year', T.StringType(), True),\n",
    "    T.StructField('Outlet_Size', T.StringType(), True),\n",
    "    T.StructField('Outlet_Location_Type', T.StringType(), True),\n",
    "    T.StructField('Outlet_Type', T.StringType(), True),\n",
    "    T.StructField('Item_Outlet_Sales', T.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c763d184-253a-490f-b322-5dd29d778cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1_custom_type = spark.read.format('csv')\\\n",
    "  .schema(my_struct_schema) \\\n",
    "    .option('header', True) \\\n",
    "      .load('/Volumes/workspace/learn/test_volume/BigMart Sales.csv')\n",
    "\n",
    "display(df1_custom_type)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_Tutorial",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
